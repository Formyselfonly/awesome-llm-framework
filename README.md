# Awesome LLM Frameworks

## **You don't need to master every framework!**

Choosing the right framework for working with Large Language Models (LLMs) can be overwhelming. Instead of wasting time comparing countless options, just pick one that suits your needs and stick with it. Avoid overcomplicating your workflow by using too many frameworks.

Such as play badminton,don't waste your time on choose your badminton racket,you should focus on improving yourself ability!

## **Recommended LLM Frameworks & Tools**

### **1. AI Deployment**

For easily deploying LLMs, this combination offers a powerful and user-friendly setup:
Use Ollama for deploy LLMs and use Open Web UI for LLMs deploy and manage UI.

- **[Ollama](https://ollama.com/)** – A simple, efficient way to run and manage local LLMs.
- **[Open Web UI](https://github.com/open-webui/open-webui)** – A sleek web interface for interacting with deployed models.

### **2. AI Technology Stack**

For building AI-powered applications, these frameworks provide robust capabilities:
Use Dify for LLMOPs and use RAGFLOW external Knowledge for Dify.

- **[Dify](https://dify.ai/)** – A powerful AI development platform with workflow automation.
- **[RAGFlow](https://ragflow.io/docs/dev/)** – An advanced Retrieval-Augmented Generation (RAG) framework for improving LLM responses with external data.

------

## **Detailed Overview: Key LLM Technologies & Frameworks**

### **1. Prompt Engineering**

Prompt engineering is crucial for optimizing LLM performance. Use this resource to refine your prompts:

- **[Prompt Guide](https://www.promptingguide.ai/)** – A comprehensive guide to crafting effective AI prompts.

### **2. Retrieval-Augmented Generation (RAG)**

Enhance LLMs with external knowledge using RAG methodologies:

- **[RAGFlow](https://ragflow.io/docs/dev/)** – A practical toolkit for implementing RAG-based AI solutions.

### **3. AI Agents, Workflows & AI UI**

Automate tasks and build AI-driven workflows:

- **[Dify](https://dify.ai/)** – A full-featured framework for building AI-powered applications with no-code and low-code capabilities.

### **4. Model Context Protocol(MCP)**

#### **Client-Side**

- **[Cline](https://github.com/cline/cline)**

#### **Server-Side**

- **[Awesome-MCP-Servers](https://github.com/punkpeye/awesome-mcp-servers)**

# Awesome LLM Frameworks-CN Version

## **你不需要掌握每一个框架！**

在大语言模型（LLM）领域选择合适的框架可能会让人感到困惑。与其浪费时间比较无数选项，不如挑选一个适合自己的，并坚持使用它。避免使用过多的框架让你的工作流程变得复杂。

就像打羽毛球一样，不要把时间浪费在选择球拍上，而是应该专注于提高自己的技术！

## **推荐的 LLM 框架和工具**

### **1. AI 部署**

如果你想轻松部署 LLMs，这个组合提供了强大且用户友好的解决方案： 使用 Ollama 来部署 LLMs，并使用 Open Web UI 进行 LLMs 的部署和管理。

- [**Ollama**](https://ollama.com/) – 轻量、高效的本地 LLM 运行和管理工具。
- [**Open Web UI**](https://github.com/open-webui/open-webui) – 交互式 LLM 部署管理的精美 Web 界面。

### **2. AI 技术栈**

如果你正在构建 AI 应用，这些框架提供了强大的功能： 使用 Dify 进行 LLMOps，结合 RAGFlow 提供的外部知识增强 Dify。

- [**Dify**](https://dify.ai/) – 强大的 AI 开发平台，支持自动化工作流。
- [**RAGFlow**](https://ragflow.io/docs/dev/) – 先进的检索增强生成（RAG）框架，可通过外部知识提升 LLM 响应质量。

## **详细解析：关键 LLM 技术和框架**

### **1. 提示词工程（Prompt Engineering）**

提示词优化对于提高 LLM 的表现至关重要。以下资源可帮助你优化提示词：

- [**Prompt Guide**](https://www.promptingguide.ai/) – 详尽的 AI 提示词优化指南。

### **2. 检索增强生成（RAG）**

使用 RAG 方法增强 LLM 访问外部知识的能力：

- [**RAGFlow**](https://ragflow.io/docs/dev/) – 实用的 RAG 解决方案工具包。

### **3. AI 代理、工作流 & AI UI**

自动化任务并构建 AI 驱动的工作流：

- [**Dify**](https://dify.ai/) – 全功能 AI 开发框架，支持无代码和低代码应用。

### **4. 模型上下文协议（Model Context Protocol，MCP）**

#### **客户端**

- [**Cline**](https://github.com/cline/cline)

#### **服务器端**

- [**Awesome-MCP-Servers**](https://github.com/punkpeye/awesome-mcp-servers)
